# scripts/migrate_images_to_s3.py
import asyncio
import io
from datetime import datetime
from typing import Optional, List, Dict, Any

import aiohttp
import boto3
import psycopg2
from PIL import Image
from botocore.exceptions import ClientError
from psycopg2.extras import RealDictCursor

from core.config import settings

# ì„¤ì •ê°’ë“¤
AWS_S3_BUCKET = "serenade-prod-images"  # S3 ë²„í‚·ëª…
AWS_REGION = "ap-northeast-2"  # AWS ë¦¬ì „
CLOUDFRONT_DOMAIN = "d8erw6l13w214.cloudfront.net"  # CloudFront ë„ë©”ì¸ (ë°°í¬ í›„ ì„¤ì •)
USE_CLOUDFRONT = True  # CloudFront ì‚¬ìš© ì—¬ë¶€
MAX_CONCURRENT_DOWNLOADS = 10  # ë™ì‹œ ë‹¤ìš´ë¡œë“œ ìˆ˜
CHUNK_SIZE = 100  # í•œ ë²ˆì— ì²˜ë¦¬í•  ì´ë¯¸ì§€ ìˆ˜


# PostgreSQL ì—°ê²° ì •ë³´ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
DB_CONFIG = {
    "host": settings.POSTGRES_SERVER,
    "database": settings.POSTGRES_DB,
    "user": settings.POSTGRES_USER,
    "password": settings.POSTGRES_PASSWORD,
    "port": settings.POSTGRES_PORT,
}


class ImageMigrator:
    def __init__(self):
        # S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.s3_client = boto3.client("s3", region_name=AWS_REGION)
        self.session = None

        # í†µê³„ìš© ë³€ìˆ˜ë“¤
        self.stats = {"total": 0, "success": 0, "failed": 0, "skipped": 0, "errors": []}

    def get_db_connection(self):
        """PostgreSQL ì—°ê²°"""
        try:
            conn = psycopg2.connect(**DB_CONFIG, cursor_factory=RealDictCursor)
            return conn
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            raise

    def generate_s3_key(
        self,
        image_id: int,
        product_id: int,
        product_venue_id: int = None,
        image_type: str = None,
    ) -> str:
        """S3 í‚¤ ìƒì„± (ê²½ë¡œ êµ¬ì¡°: product_id/venue_id/image_type_image_id.webp)"""
        # ì´ë¯¸ì§€ íƒ€ì…ì„ íŒŒì¼ëª…ì— í¬í•¨
        if image_type:
            # ì´ë¯¸ì§€ íƒ€ì…ì„ ì•ˆì „í•œ íŒŒì¼ëª…ìœ¼ë¡œ ë³€í™˜
            safe_type = "".join(
                c if c.isalnum() or c in "-_" else "_" for c in image_type
            )
            filename = f"{safe_type}_{image_id}.webp"
        else:
            filename = f"{image_id}.webp"

        # ê¸°ë³¸ ê²½ë¡œ: products/{product_id}
        path_parts = ["products", str(product_id)]

        # venue_idê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if product_venue_id:
            path_parts.append(f"venue_{product_venue_id}")
        else:
            path_parts.append("common")  # venueê°€ ì—†ëŠ” ê³µí†µ ì´ë¯¸ì§€

        # ìµœì¢… ê²½ë¡œ ìƒì„±
        path_parts.append(filename)
        return "/".join(path_parts)

    def generate_s3_url(self, s3_key: str) -> str:
        """S3 ë˜ëŠ” CloudFront URL ìƒì„±"""
        if USE_CLOUDFRONT and CLOUDFRONT_DOMAIN:
            return f"https://{CLOUDFRONT_DOMAIN}/{s3_key}"
        else:
            return f"https://{AWS_S3_BUCKET}.s3.{AWS_REGION}.amazonaws.com/{s3_key}"

    async def download_image(
        self, session: aiohttp.ClientSession, url: str
    ) -> Optional[bytes]:
        """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
        try:
            # íƒ€ì„ì•„ì›ƒ ì„¤ì • (ì—°ê²° 10ì´ˆ, ì½ê¸° 30ì´ˆ)
            timeout = aiohttp.ClientTimeout(connect=10, total=30)

            async with session.get(url, timeout=timeout) as response:
                if response.status == 200:
                    return await response.read()
                else:
                    print(f"  âš ï¸  HTTP {response.status}: {url}")
                    return None

        except asyncio.TimeoutError:
            print(f"  â° íƒ€ì„ì•„ì›ƒ: {url}")
            return None
        except Exception as e:
            print(f"  âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {url} - {e}")
            return None

    def convert_to_webp(self, image_data: bytes, quality: int = 85) -> Optional[bytes]:
        """ì´ë¯¸ì§€ë¥¼ WebPë¡œ ë³€í™˜"""
        try:
            # PILë¡œ ì´ë¯¸ì§€ ì—´ê¸°
            with Image.open(io.BytesIO(image_data)) as img:
                # RGBAë¥¼ RGBë¡œ ë³€í™˜ (WebP í˜¸í™˜ì„±ì„ ìœ„í•´)
                if img.mode in ("RGBA", "LA", "P"):
                    background = Image.new("RGB", img.size, (255, 255, 255))
                    if img.mode == "P":
                        img = img.convert("RGBA")
                    if img.mode in ("RGBA", "LA"):
                        background.paste(
                            img, mask=img.split()[-1] if img.mode == "RGBA" else None
                        )
                    img = background
                elif img.mode != "RGB":
                    img = img.convert("RGB")

                # WebPë¡œ ë³€í™˜
                output = io.BytesIO()
                img.save(output, format="WEBP", quality=quality, optimize=True)
                return output.getvalue()

        except Exception as e:
            print(f"  âŒ ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None

    def upload_to_s3(self, s3_key: str, image_data: bytes) -> bool:
        """S3ì— ì´ë¯¸ì§€ ì—…ë¡œë“œ"""
        try:
            self.s3_client.put_object(
                Bucket=AWS_S3_BUCKET,
                Key=s3_key,
                Body=image_data,
                ContentType="image/webp",
                CacheControl="max-age=31536000",  # 1ë…„ ìºì‹œ
                Metadata={
                    "uploaded_at": datetime.now().isoformat(),
                    "converted_format": "webp",
                },
            )
            return True

        except ClientError as e:
            print(f"  âŒ S3 ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
        except Exception as e:
            print(f"  âŒ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
            return False

    def update_image_url_in_db(self, image_id: int, new_url: str):
        """ë°ì´í„°ë² ì´ìŠ¤ì˜ ì´ë¯¸ì§€ URL ì—…ë°ì´íŠ¸"""
        try:
            conn = self.get_db_connection()
            cursor = conn.cursor()

            update_query = """
                UPDATE product_images 
                SET image_url = %s, updated_datetime = %s 
                WHERE id = %s
            """

            cursor.execute(update_query, (new_url, datetime.now(), image_id))
            conn.commit()

            cursor.close()
            conn.close()
            return True

        except Exception as e:
            print(f"  âŒ DB ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False

    async def process_image(
        self, session: aiohttp.ClientSession, image_record: Dict[str, Any]
    ) -> bool:
        """ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬"""
        image_id = image_record["id"]
        product_id = image_record["product_id"]
        product_venue_id = image_record.get("product_venue_id")
        original_url = image_record["image_url"]
        image_type = image_record.get("image_type", "general")

        print(
            f"  ğŸ“¥ ì²˜ë¦¬ ì¤‘: ID={image_id}, Product={product_id}, Venue={product_venue_id}, Type={image_type}"
        )
        print(f"      ì›ë³¸: {original_url}")

        # S3 í‚¤ ìƒì„±
        s3_key = self.generate_s3_key(
            image_id, product_id, product_venue_id, image_type
        )
        s3_url = self.generate_s3_url(s3_key)

        print(f"      ì €ì¥ ê²½ë¡œ: {s3_key}")

        # S3ì— ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        try:
            self.s3_client.head_object(Bucket=AWS_S3_BUCKET, Key=s3_key)
            print(f"  âš ï¸  ì´ë¯¸ ì¡´ì¬í•¨, ìŠ¤í‚µ: {s3_key}")

            # DB URLë§Œ ì—…ë°ì´íŠ¸
            if self.update_image_url_in_db(image_id, s3_url):
                self.stats["skipped"] += 1
                return True
            else:
                self.stats["failed"] += 1
                return False

        except ClientError:
            # íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ, ê³„ì† ì§„í–‰
            pass

        # 1. ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        image_data = await self.download_image(session, original_url)
        if not image_data:
            self.stats["failed"] += 1
            self.stats["errors"].append(
                f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: ID={image_id}, URL={original_url}"
            )
            return False

        # 2. WebPë¡œ ë³€í™˜
        webp_data = self.convert_to_webp(image_data)
        if not webp_data:
            self.stats["failed"] += 1
            self.stats["errors"].append(f"ë³€í™˜ ì‹¤íŒ¨: ID={image_id}")
            return False

        # 3. S3 ì—…ë¡œë“œ
        if not self.upload_to_s3(s3_key, webp_data):
            self.stats["failed"] += 1
            self.stats["errors"].append(f"S3 ì—…ë¡œë“œ ì‹¤íŒ¨: ID={image_id}, Key={s3_key}")
            return False

        # 4. DB URL ì—…ë°ì´íŠ¸
        if not self.update_image_url_in_db(image_id, s3_url):
            self.stats["failed"] += 1
            self.stats["errors"].append(f"DB ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: ID={image_id}")
            return False

        print(f"  âœ… ì™„ë£Œ: {s3_url}")
        self.stats["success"] += 1
        return True

    async def process_image_batch(self, image_records: List[Dict[str, Any]]):
        """ì´ë¯¸ì§€ ë°°ì¹˜ ì²˜ë¦¬"""
        connector = aiohttp.TCPConnector(limit=MAX_CONCURRENT_DOWNLOADS)
        timeout = aiohttp.ClientTimeout(total=60)

        async with aiohttp.ClientSession(
            connector=connector, timeout=timeout
        ) as session:
            # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ ë‹¤ìš´ë¡œë“œ ìˆ˜ ì œí•œ
            semaphore = asyncio.Semaphore(MAX_CONCURRENT_DOWNLOADS)

            async def process_with_semaphore(image_record):
                async with semaphore:
                    return await self.process_image(session, image_record)

            # ëª¨ë“  ì´ë¯¸ì§€ ë³‘ë ¬ ì²˜ë¦¬
            tasks = [process_with_semaphore(record) for record in image_records]
            await asyncio.gather(*tasks, return_exceptions=True)

    def get_image_records(
        self, offset: int = 0, limit: int = CHUNK_SIZE
    ) -> List[Dict[str, Any]]:
        """DBì—ì„œ ì´ë¯¸ì§€ ë ˆì½”ë“œ ì¡°íšŒ"""
        conn = self.get_db_connection()
        cursor = conn.cursor()

        query = """
            SELECT id, image_url, image_type, product_id, product_venue_id
            FROM product_images 
            WHERE is_deleted = false 
            AND image_url IS NOT NULL 
            AND image_url != ''
            ORDER BY product_id, product_venue_id, image_type, id
            LIMIT %s OFFSET %s
        """

        cursor.execute(query, (limit, offset))
        records = cursor.fetchall()

        cursor.close()
        conn.close()

        return [dict(record) for record in records]

    def get_total_count(self) -> int:
        """ì „ì²´ ì´ë¯¸ì§€ ìˆ˜ ì¡°íšŒ"""
        conn = self.get_db_connection()
        cursor = conn.cursor()

        query = """
            SELECT COUNT(*) as total
            FROM product_images 
            WHERE is_deleted = false 
            AND image_url IS NOT NULL 
            AND image_url != ''
        """

        cursor.execute(query)
        result = cursor.fetchone()

        cursor.close()
        conn.close()

        return result["total"]

    async def run_migration(self):
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰"""
        print("ğŸš€ ì´ë¯¸ì§€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
        print(f"ğŸ“Š ëŒ€ìƒ ë²„í‚·: {AWS_S3_BUCKET}")
        print(f"ğŸ”§ ì„¤ì •: ë™ì‹œì²˜ë¦¬={MAX_CONCURRENT_DOWNLOADS}, ë°°ì¹˜í¬ê¸°={CHUNK_SIZE}")

        # ì „ì²´ ì´ë¯¸ì§€ ìˆ˜ í™•ì¸
        total_count = self.get_total_count()
        self.stats["total"] = total_count

        print(f"ğŸ“ˆ ì´ ì²˜ë¦¬ ëŒ€ìƒ: {total_count}ê°œ ì´ë¯¸ì§€")

        if total_count == 0:
            print("âŒ ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        offset = 0
        batch_num = 1

        while offset < total_count:
            print(f"\nğŸ“¦ ë°°ì¹˜ {batch_num} ì²˜ë¦¬ ì¤‘ (ì˜¤í”„ì…‹: {offset})")

            # ë°°ì¹˜ ë°ì´í„° ì¡°íšŒ
            image_records = self.get_image_records(offset, CHUNK_SIZE)

            if not image_records:
                break

            # ë°°ì¹˜ ì²˜ë¦¬
            await self.process_image_batch(image_records)

            # ì§„í–‰ë¥  ì¶œë ¥
            processed = min(offset + CHUNK_SIZE, total_count)
            progress = (processed / total_count) * 100
            print(f"ğŸ“Š ì§„í–‰ë¥ : {processed}/{total_count} ({progress:.1f}%)")

            offset += CHUNK_SIZE
            batch_num += 1

        # ìµœì¢… ê²°ê³¼ ì¶œë ¥
        self.print_final_stats()

    def print_final_stats(self):
        """ìµœì¢… í†µê³„ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
        print("=" * 60)
        print(f"ğŸ“Š ì´ ì²˜ë¦¬ ëŒ€ìƒ: {self.stats['total']}ê°œ")
        print(f"âœ… ì„±ê³µ: {self.stats['success']}ê°œ")
        print(f"âš ï¸  ìŠ¤í‚µ: {self.stats['skipped']}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {self.stats['failed']}ê°œ")

        if self.stats["errors"]:
            print(f"\nâŒ ì˜¤ë¥˜ ëª©ë¡ (ìµœëŒ€ 10ê°œ):")
            for error in self.stats["errors"][:10]:
                print(f"  - {error}")

            if len(self.stats["errors"]) > 10:
                print(f"  ... ì™¸ {len(self.stats['errors']) - 10}ê°œ ë”")

        success_rate = (
            (self.stats["success"] / self.stats["total"]) * 100
            if self.stats["total"] > 0
            else 0
        )
        print(f"\nğŸ“ˆ ì„±ê³µë¥ : {success_rate:.1f}%")


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        migrator = ImageMigrator()
        await migrator.run_migration()

    except KeyboardInterrupt:
        print("\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"\nâŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        raise


if __name__ == "__main__":
    # ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
    asyncio.run(main())
